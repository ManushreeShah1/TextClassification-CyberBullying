{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89c6c4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.9.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wordcloud) (9.0.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wordcloud) (1.21.6)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wordcloud) (3.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "884be1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.17.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2022.3.15)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56ea05ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.13.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f2e18c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (61.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Collecting numpy<=1.24.3,>=1.22\n",
      "  Using cached numpy-1.24.3-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.56.2)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.13.0->tensorflow) (3.0.4)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.6\n",
      "    Uninstalling numpy-1.21.6:\n",
      "      Successfully uninstalled numpy-1.21.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Hp\\\\anaconda3\\\\Lib\\\\site-packages\\\\~0mpy\\\\.libs\\\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ad953aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-utils in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.0.13)\n",
      "Requirement already satisfied: Keras>=2.1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras-utils) (2.13.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3004098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.25.2-cp39-cp39-win_amd64.whl (15.6 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.11.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from seaborn) (1.4.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "Successfully installed numpy-1.25.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.5.0 requires daal==2021.4.0, which is not installed.\n",
      "tensorflow-intel 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 1.25.2 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.25.2 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy scipy seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a921ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import string\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import word2vec\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "# from keras.layers.convolutional import Conv1D\n",
    "# from keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b4ff1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.4.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2022.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f464be6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\hp\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n",
      "Requirement already satisfied: anyascii in c:\\users\\hp\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7148ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.42.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Hp\\\\anaconda3\\\\Lib\\\\site-packages\\\\~1mpy\\\\.libs\\\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (1.0.2)\n",
      "Requirement already satisfied: numba in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (0.55.1)\n",
      "Requirement already satisfied: slicer==0.0.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (1.25.2)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (21.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (1.11.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (2.0.0)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (4.64.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging>20.9->shap) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.4)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from numba->shap) (0.38.0)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.21.6-cp39-cp39-win_amd64.whl (14.0 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from numba->shap) (61.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas->shap) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (1.1.0)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.2\n",
      "    Uninstalling numpy-1.25.2:\n",
      "      Successfully uninstalled numpy-1.25.2\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb8dc95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.42.1)\n",
      "Requirement already satisfied: numba in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.55.1)\n",
      "Collecting numba\n",
      "  Using cached numba-0.57.1-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (1.11.1)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (4.64.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (1.4.2)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (2.0.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (21.3)\n",
      "Collecting llvmlite<0.41,>=0.40.0dev0\n",
      "  Using cached llvmlite-0.40.1-cp39-cp39-win_amd64.whl (27.7 MB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging>20.9->shap) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas->shap) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (1.1.0)\n",
      "Installing collected packages: llvmlite, numba\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.38.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade shap numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3dccc0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "initialization of _internal failed without raising an exception",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcontractions\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\__init__.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[0;32m      3\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.42.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_explanation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Explanation, Cohorts\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# explainers\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplainers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_explainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Explainer\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\_explanation.py:13\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mslicer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Alias, Obj, Slicer\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DimensionError\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_general\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpChain\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# slicer confuses pylint...\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# pylint: disable=no-member\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\utils\\__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_clustering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     delta_minimization_order,\n\u001b[0;32m      3\u001b[0m     hclust,\n\u001b[0;32m      4\u001b[0m     hclust_ordering,\n\u001b[0;32m      5\u001b[0m     partition_tree,\n\u001b[0;32m      6\u001b[0m     partition_tree_shuffle,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_general\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     OpChain,\n\u001b[0;32m     10\u001b[0m     approximate_interactions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     suppress_stderr,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_masked_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MaskedModel, make_masks\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\utils\\_clustering.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m njit\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_general\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m safe_isinstance\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_progress\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_progress\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\__init__.py:42\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (cfunc, generated_jit, jit, njit, stencil,\n\u001b[0;32m     39\u001b[0m                                    jit_module)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Re-export vectorize decorators and the thread layer querying function\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mufunc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (vectorize, guvectorize, threading_layer,\n\u001b[0;32m     43\u001b[0m                             get_num_threads, set_num_threads)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Re-export Numpy helpers\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy_support\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m carray, farray, from_dtype\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\np\\ufunc\\__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mufunc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Vectorize, GUVectorize, vectorize, guvectorize\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mufunc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PyUFunc_None, PyUFunc_Zero, PyUFunc_One\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mufunc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _internal, array_exprs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\np\\ufunc\\decorators.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mufunc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _internal\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mufunc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelUFuncBuilder, ParallelGUFuncBuilder\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DelayedRegistry\n",
      "\u001b[1;31mSystemError\u001b[0m: initialization of _internal failed without raising an exception"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import (AutoTokenizer, \n",
    "                          AutoModelForSequenceClassification, \n",
    "                          TextClassificationPipeline)\n",
    "\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import contractions\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51cf42e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0388411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"twitter_parsed_dataset.csv\").drop(columns=['id','index','Annotation'])\n",
    "data.columns=['text','label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03861605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16846</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16848</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16851 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...    0.0\n",
       "1      @ShreyaBafna3 Now you idiots claim that people...    0.0\n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...    1.0\n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...    1.0\n",
       "4                                 #mkr No No No No No No    0.0\n",
       "...                                                  ...    ...\n",
       "16846  Feeling so sorry for the girls, they should be...    0.0\n",
       "16847  #MKR 'pretty good dishes we're happy with' - O...    0.0\n",
       "16848  RT @colonelkickhead: Deconstructed lemon tart!...    0.0\n",
       "16849  @versacezaynx @nyazpolitics @greenlinerzjm You...    0.0\n",
       "16850  And before you protest that you're *not* mad, ...    0.0\n",
       "\n",
       "[16851 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bab68ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kat and Andre make me want to punch happy things 😡 #mkr'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].sample(1).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5f51bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@halalflaws @biebervalue @greenlinerzjm I read them in context.No change in meaning. The history of Islamic slavery. https://t.co/xWJzpSodGj'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "892504df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x25c6092f7f0>,\n",
       "  <matplotlib.axis.XTick at 0x25c6092f7c0>],\n",
       " [Text(0, 0, 'positive'), Text(1, 0, 'negative')])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar',color=sns.color_palette('pastel'))\n",
    "plt.xticks([0,1],['positive','negative'],rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4340e718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar',color=sns.color_palette('pastel'))\n",
    "plt.xticks([0,1],['positive','negative'],rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8a21d2",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04ebcd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading words: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98f3b96c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "only_english=set(nltk.corpus.words.words())\n",
    "def clean_text(text):\n",
    "    \n",
    "    sample=text\n",
    "    sample=\" \".join([x.lower() for x in sample.split()])\n",
    "    sample=re.sub(r\"\\S*https?:\\S*\",'',sample) #links and urls\n",
    "    sample=re.sub('\\[.*?\\]','',sample) #text between square brackets\n",
    "    sample=re.sub('\\(.*?\\)','',sample)\n",
    "    sample=re.sub('#','',sample) #remove hashtags\n",
    "    sample=''.join([x for x in sample.split() if not x.startswith('@')]) #remove mentions with @\n",
    "    sample = \" \".join([contractions.fix(x) for x in sample.split()])  # fixes contractions like you're to you are\n",
    "    sample=re.sub('[%s]'% re.escape(string.punctuation),'',sample) #punctuation\n",
    "    sample = re.sub('\\w*\\d\\w', '', sample) #digits with trailing or preceeding text\n",
    "    sample = re.sub(r'\\n', ' ', sample) #new line character\n",
    "    sample = re.sub(r'\\\\n', ' ', sample) #new line character\n",
    "    sample = re.sub(\"[''\"\"...“”‘’…]\", '', sample) #list of quotation marks\n",
    "    sample = \" \".join(x.strip() for x in sample.split()) #strips whitespace\n",
    "    sample = re.sub(r', /<[^>]+>/', '', sample)    #HTML attributes\n",
    "    \n",
    "    sample=''.join(list(filter(lambda ele: re.search(\"[a-zA-Z\\s]+\",ele) is not None,sample.split()))) #languages other than english\n",
    "    sample = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE).sub(r'', sample) #emojis and symbols\n",
    "    sample=sample.strip()\n",
    "    sample=\" \".join([x.strip() for x in sample.split()])\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcf4b206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8164bbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ireadthemincontextnochangeinmeaningthehistoryo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nowyouidiotsclaimthatpeoplewhotriedtostophimfr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rtcallmesexistbutwhenigotoanautoplaceidrathert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrongisisfollowstheexampleofmohammedandthequra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mkrnononononono</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16846</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feelingsosorryforthegirlstheyshouldbesafeandka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mkrprettygooddisheswerehappywithokwellimnevere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16848</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rtdeconstructedlemontartcanwepleasegojustonese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>youaretoostupidtotalktoblocked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>andbeforeyouprotestthatyourenotmadtheresnotmuc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16851 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...    0.0   \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...    0.0   \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...    1.0   \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...    1.0   \n",
       "4                                 #mkr No No No No No No    0.0   \n",
       "...                                                  ...    ...   \n",
       "16846  Feeling so sorry for the girls, they should be...    0.0   \n",
       "16847  #MKR 'pretty good dishes we're happy with' - O...    0.0   \n",
       "16848  RT @colonelkickhead: Deconstructed lemon tart!...    0.0   \n",
       "16849  @versacezaynx @nyazpolitics @greenlinerzjm You...    0.0   \n",
       "16850  And before you protest that you're *not* mad, ...    0.0   \n",
       "\n",
       "                                            cleaned_text  \n",
       "0      ireadthemincontextnochangeinmeaningthehistoryo...  \n",
       "1      nowyouidiotsclaimthatpeoplewhotriedtostophimfr...  \n",
       "2      rtcallmesexistbutwhenigotoanautoplaceidrathert...  \n",
       "3      wrongisisfollowstheexampleofmohammedandthequra...  \n",
       "4                                        mkrnononononono  \n",
       "...                                                  ...  \n",
       "16846  feelingsosorryforthegirlstheyshouldbesafeandka...  \n",
       "16847  mkrprettygooddisheswerehappywithokwellimnevere...  \n",
       "16848  rtdeconstructedlemontartcanwepleasegojustonese...  \n",
       "16849                     youaretoostupidtotalktoblocked  \n",
       "16850  andbeforeyouprotestthatyourenotmadtheresnotmuc...  \n",
       "\n",
       "[16851 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cleaned_text']=data['text'].apply(lambda x: clean_text(str(x)))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac60f128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ba9a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops=set(stopwords.words('english'))\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "ps=PorterStemmer()\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    treebank_tag=nltk.pos_tag([word])[0][1]\n",
    "    \n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "def correct_text(text,stem=False,lemma=False,spell=False):\n",
    "    if lemma and stem:\n",
    "        raise Exception('Either stem or lemma can be true,not both!')\n",
    "        return text\n",
    "    \n",
    "    sample=text\n",
    "    \n",
    "    #removing stopwords\n",
    "    sample=sample.lower()\n",
    "    sample=[word for word in sample.split() if not word in stops]\n",
    "    sample=''.join(sample)\n",
    "    \n",
    "    if lemma:\n",
    "        sample=sample.split()\n",
    "        sample=[lemmatizer.lemmatize(word.lower(),get_wordnet_pos(word.lower())) for word in sample]\n",
    "        sample=''.join(sample)\n",
    "        \n",
    "    if spell:\n",
    "        sample=str(TextBlob(text).correct())\n",
    "        \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e3b3f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>correct_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ireadthemincontextnochangeinmeaningthehistoryo...</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nowyouidiotsclaimthatpeoplewhotriedtostophimfr...</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rtcallmesexistbutwhenigotoanautoplaceidrathert...</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrongisisfollowstheexampleofmohammedandthequra...</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mkrnononononono</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16846</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feelingsosorryforthegirlstheyshouldbesafeandka...</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mkrprettygooddisheswerehappywithokwellimnevere...</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16848</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rtdeconstructedlemontartcanwepleasegojustonese...</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>youaretoostupidtotalktoblocked</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>andbeforeyouprotestthatyourenotmadtheresnotmuc...</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16851 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...    0.0   \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...    0.0   \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...    1.0   \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...    1.0   \n",
       "4                                 #mkr No No No No No No    0.0   \n",
       "...                                                  ...    ...   \n",
       "16846  Feeling so sorry for the girls, they should be...    0.0   \n",
       "16847  #MKR 'pretty good dishes we're happy with' - O...    0.0   \n",
       "16848  RT @colonelkickhead: Deconstructed lemon tart!...    0.0   \n",
       "16849  @versacezaynx @nyazpolitics @greenlinerzjm You...    0.0   \n",
       "16850  And before you protest that you're *not* mad, ...    0.0   \n",
       "\n",
       "                                            cleaned_text correct_text  \n",
       "0      ireadthemincontextnochangeinmeaningthehistoryo...         text  \n",
       "1      nowyouidiotsclaimthatpeoplewhotriedtostophimfr...         text  \n",
       "2      rtcallmesexistbutwhenigotoanautoplaceidrathert...         text  \n",
       "3      wrongisisfollowstheexampleofmohammedandthequra...         text  \n",
       "4                                        mkrnononononono         text  \n",
       "...                                                  ...          ...  \n",
       "16846  feelingsosorryforthegirlstheyshouldbesafeandka...         text  \n",
       "16847  mkrprettygooddisheswerehappywithokwellimnevere...         text  \n",
       "16848  rtdeconstructedlemontartcanwepleasegojustonese...         text  \n",
       "16849                     youaretoostupidtotalktoblocked         text  \n",
       "16850  andbeforeyouprotestthatyourenotmadtheresnotmuc...         text  \n",
       "\n",
       "[16851 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['correct_text']='text'\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b0c98c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5dce8f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [WinError 10060] A connection attempt failed because\n",
      "[nltk_data]     the connected party did not properly respond after a\n",
      "[nltk_data]     period of time, or established connection failed\n",
      "[nltk_data]     because connected host has failed to respond>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n",
      "[nltk_data] Error loading omw-1.4: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7471ed39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16851 [00:00<?, ?it/s]C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_15344\\716725424.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['correct_text'][count]=correct_text(text,lemma=True)\n",
      "100%|██████████| 16851/16851 [13:46<00:00, 20.39it/s]\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for text in tqdm(data['cleaned_text']):\n",
    "    data['correct_text'][count]=correct_text(text,lemma=True)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "172c60f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['word_count']=data['correct_text'].apply(lambda x: len(str(x).split(\"\")))\n",
    "# data['char_count']=data['correct_text'].str.len() #this also includes spaces\n",
    "data['word_count'] = data['correct_text'].apply(lambda x: len(str(x).split()))\n",
    "data['char_count'] = data['correct_text'].str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "613f79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>correct_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ireadthemincontextnochangeinmeaningthehistoryo...</td>\n",
       "      <td>ireadthemincontextnochangeinmeaningthehistoryo...</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nowyouidiotsclaimthatpeoplewhotriedtostophimfr...</td>\n",
       "      <td>nowyouidiotsclaimthatpeoplewhotriedtostophimfr...</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rtcallmesexistbutwhenigotoanautoplaceidrathert...</td>\n",
       "      <td>rtcallmesexistbutwhenigotoanautoplaceidrathert...</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrongisisfollowstheexampleofmohammedandthequra...</td>\n",
       "      <td>wrongisisfollowstheexampleofmohammedandthequra...</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mkrnononononono</td>\n",
       "      <td>mkrnononononono</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16846</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feelingsosorryforthegirlstheyshouldbesafeandka...</td>\n",
       "      <td>feelingsosorryforthegirlstheyshouldbesafeandka...</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mkrprettygooddisheswerehappywithokwellimnevere...</td>\n",
       "      <td>mkrprettygooddisheswerehappywithokwellimnevere...</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16848</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rtdeconstructedlemontartcanwepleasegojustonese...</td>\n",
       "      <td>rtdeconstructedlemontartcanwepleasegojustonese...</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>youaretoostupidtotalktoblocked</td>\n",
       "      <td>youaretoostupidtotalktoblocked</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>andbeforeyouprotestthatyourenotmadtheresnotmuc...</td>\n",
       "      <td>andbeforeyouprotestthatyourenotmadtheresnotmuc...</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16851 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...    0.0   \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...    0.0   \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...    1.0   \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...    1.0   \n",
       "4                                 #mkr No No No No No No    0.0   \n",
       "...                                                  ...    ...   \n",
       "16846  Feeling so sorry for the girls, they should be...    0.0   \n",
       "16847  #MKR 'pretty good dishes we're happy with' - O...    0.0   \n",
       "16848  RT @colonelkickhead: Deconstructed lemon tart!...    0.0   \n",
       "16849  @versacezaynx @nyazpolitics @greenlinerzjm You...    0.0   \n",
       "16850  And before you protest that you're *not* mad, ...    0.0   \n",
       "\n",
       "                                            cleaned_text  \\\n",
       "0      ireadthemincontextnochangeinmeaningthehistoryo...   \n",
       "1      nowyouidiotsclaimthatpeoplewhotriedtostophimfr...   \n",
       "2      rtcallmesexistbutwhenigotoanautoplaceidrathert...   \n",
       "3      wrongisisfollowstheexampleofmohammedandthequra...   \n",
       "4                                        mkrnononononono   \n",
       "...                                                  ...   \n",
       "16846  feelingsosorryforthegirlstheyshouldbesafeandka...   \n",
       "16847  mkrprettygooddisheswerehappywithokwellimnevere...   \n",
       "16848  rtdeconstructedlemontartcanwepleasegojustonese...   \n",
       "16849                     youaretoostupidtotalktoblocked   \n",
       "16850  andbeforeyouprotestthatyourenotmadtheresnotmuc...   \n",
       "\n",
       "                                            correct_text  word_count  \\\n",
       "0      ireadthemincontextnochangeinmeaningthehistoryo...           1   \n",
       "1      nowyouidiotsclaimthatpeoplewhotriedtostophimfr...           1   \n",
       "2      rtcallmesexistbutwhenigotoanautoplaceidrathert...           1   \n",
       "3      wrongisisfollowstheexampleofmohammedandthequra...           1   \n",
       "4                                        mkrnononononono           1   \n",
       "...                                                  ...         ...   \n",
       "16846  feelingsosorryforthegirlstheyshouldbesafeandka...           1   \n",
       "16847  mkrprettygooddisheswerehappywithokwellimnevere...           1   \n",
       "16848  rtdeconstructedlemontartcanwepleasegojustonese...           1   \n",
       "16849                     youaretoostupidtotalktoblocked           1   \n",
       "16850  andbeforeyouprotestthatyourenotmadtheresnotmuc...           1   \n",
       "\n",
       "       char_count  \n",
       "0              61  \n",
       "1             103  \n",
       "2              55  \n",
       "3              54  \n",
       "4              15  \n",
       "...           ...  \n",
       "16846          75  \n",
       "16847          62  \n",
       "16848          98  \n",
       "16849          30  \n",
       "16850          95  \n",
       "\n",
       "[16851 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d451714a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         61\n",
       "1        103\n",
       "2         55\n",
       "3         54\n",
       "4         15\n",
       "        ... \n",
       "16846     75\n",
       "16847     62\n",
       "16848     98\n",
       "16849     30\n",
       "16850     95\n",
       "Name: char_count, Length: 16851, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "data['char_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1c303a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[~(data['char_count']==0)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42c786d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>correct_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ireadthemincontextnochangeinmeaningthehistoryo...</td>\n",
       "      <td>ireadthemincontextnochangeinmeaningthehistoryo...</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nowyouidiotsclaimthatpeoplewhotriedtostophimfr...</td>\n",
       "      <td>nowyouidiotsclaimthatpeoplewhotriedtostophimfr...</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mkrnononononono</td>\n",
       "      <td>mkrnononononono</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rtsaudipreacherwhorapedandtorturedhisfiveyearo...</td>\n",
       "      <td>rtsaudipreacherwhorapedandtorturedhisfiveyearo...</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Going to make some pancakes.....Don't hve any ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>goingtomakesomepancakesdonthveanystrawberriesb...</td>\n",
       "      <td>goingtomakesomepancakesdonthveanystrawberriesb...</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16273</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feelingsosorryforthegirlstheyshouldbesafeandka...</td>\n",
       "      <td>feelingsosorryforthegirlstheyshouldbesafeandka...</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16274</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mkrprettygooddisheswerehappywithokwellimnevere...</td>\n",
       "      <td>mkrprettygooddisheswerehappywithokwellimnevere...</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rtdeconstructedlemontartcanwepleasegojustonese...</td>\n",
       "      <td>rtdeconstructedlemontartcanwepleasegojustonese...</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>youaretoostupidtotalktoblocked</td>\n",
       "      <td>youaretoostupidtotalktoblocked</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>andbeforeyouprotestthatyourenotmadtheresnotmuc...</td>\n",
       "      <td>andbeforeyouprotestthatyourenotmadtheresnotmuc...</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10995 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...    0.0   \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...    0.0   \n",
       "4                                 #mkr No No No No No No    0.0   \n",
       "5      RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...    0.0   \n",
       "7      Going to make some pancakes.....Don't hve any ...    0.0   \n",
       "...                                                  ...    ...   \n",
       "16273  Feeling so sorry for the girls, they should be...    0.0   \n",
       "16274  #MKR 'pretty good dishes we're happy with' - O...    0.0   \n",
       "16275  RT @colonelkickhead: Deconstructed lemon tart!...    0.0   \n",
       "16276  @versacezaynx @nyazpolitics @greenlinerzjm You...    0.0   \n",
       "16277  And before you protest that you're *not* mad, ...    0.0   \n",
       "\n",
       "                                            cleaned_text  \\\n",
       "0      ireadthemincontextnochangeinmeaningthehistoryo...   \n",
       "1      nowyouidiotsclaimthatpeoplewhotriedtostophimfr...   \n",
       "4                                        mkrnononononono   \n",
       "5      rtsaudipreacherwhorapedandtorturedhisfiveyearo...   \n",
       "7      goingtomakesomepancakesdonthveanystrawberriesb...   \n",
       "...                                                  ...   \n",
       "16273  feelingsosorryforthegirlstheyshouldbesafeandka...   \n",
       "16274  mkrprettygooddisheswerehappywithokwellimnevere...   \n",
       "16275  rtdeconstructedlemontartcanwepleasegojustonese...   \n",
       "16276                     youaretoostupidtotalktoblocked   \n",
       "16277  andbeforeyouprotestthatyourenotmadtheresnotmuc...   \n",
       "\n",
       "                                            correct_text  word_count  \\\n",
       "0      ireadthemincontextnochangeinmeaningthehistoryo...           1   \n",
       "1      nowyouidiotsclaimthatpeoplewhotriedtostophimfr...           1   \n",
       "4                                        mkrnononononono           1   \n",
       "5      rtsaudipreacherwhorapedandtorturedhisfiveyearo...           1   \n",
       "7      goingtomakesomepancakesdonthveanystrawberriesb...           1   \n",
       "...                                                  ...         ...   \n",
       "16273  feelingsosorryforthegirlstheyshouldbesafeandka...           1   \n",
       "16274  mkrprettygooddisheswerehappywithokwellimnevere...           1   \n",
       "16275  rtdeconstructedlemontartcanwepleasegojustonese...           1   \n",
       "16276                     youaretoostupidtotalktoblocked           1   \n",
       "16277  andbeforeyouprotestthatyourenotmadtheresnotmuc...           1   \n",
       "\n",
       "       char_count  \n",
       "0              61  \n",
       "1             103  \n",
       "4              15  \n",
       "5              78  \n",
       "7              62  \n",
       "...           ...  \n",
       "16273          75  \n",
       "16274          62  \n",
       "16275          98  \n",
       "16276          30  \n",
       "16277          95  \n",
       "\n",
       "[10995 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data['label']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d9c3193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.9.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.5.1)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.2-cp39-cp39-win_amd64.whl (7.5 MB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wordcloud) (1.21.6)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wordcloud) (9.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-6.0.1-py3-none-any.whl (34 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.1.0-cp39-cp39-win_amd64.whl (429 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.7.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: importlib-resources, contourpy, matplotlib\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.5.1\n",
      "    Uninstalling matplotlib-3.5.1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'c:\\\\users\\\\hp\\\\anaconda3\\\\lib\\\\site-packages\\\\matplotlib\\\\backends\\\\_backend_agg.cp39-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade wordcloud matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac0a17d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'font_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfont_manager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FontProperties\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordCloud\n\u001b[0;32m      5\u001b[0m wordcloud \u001b[38;5;241m=\u001b[39m WordCloud(\n\u001b[0;32m      6\u001b[0m     width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m,\n\u001b[0;32m      7\u001b[0m     height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m,\n\u001b[0;32m      8\u001b[0m     background_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m     min_font_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m---> 10\u001b[0m     font_path\u001b[38;5;241m=\u001b[39m\u001b[43mfont_path\u001b[49m  \u001b[38;5;66;03m# Use the font path obtained from matplotlib\u001b[39;00m\n\u001b[0;32m     11\u001b[0m )\u001b[38;5;241m.\u001b[39mgenerate(g)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# plt.figure(figsize=(8, 8), facecolor=None)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# plt.imshow(wordcloud)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# plt.axis(\"off\")\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# plt.tight_layout(pad=0)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# plt.show()\u001b[39;00m\n\u001b[0;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m), facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'font_path' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "plt.figure(figsize=(8, 8), facecolor=None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "g=str(data[data['label']==0]['correct_text'])\n",
    "\n",
    "wordcloud=WordCloud(width=800,height=800,background_color='white',min_font_size=10).generate(g)\n",
    "\n",
    "#plot the wordcloud image\n",
    "plt.figure(figsize=(8,8),facecolor=None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# font_path = \"/path/to/your/truetype/font.ttf\"\n",
    "# wordcloud = WordCloud(width=800, height=800, background_color='white', min_font_size=10, font_path=font_path).generate(g)\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.rcParams['font.family'] = 'sans-serif'  # Use a different font family\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc41f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=str(data[data['label']==1]['correct_text'])\n",
    "\n",
    "wordcloud=WordCloud(width=800,height=800,background_color='black',min_font_size=10).generate(g)\n",
    "\n",
    "#plot the wordcloud image\n",
    "plt.figure(figsize=(8,8),facecolor=None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ba2bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=data.drop(columns=['text','cleaned_text','word_count','char_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e6f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f7dd16",
   "metadata": {},
   "source": [
    "# Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be88b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load doc and add to vocab\n",
    "def build_vocab(vocab_obj,text):\n",
    "    sample=text\n",
    "    tokens=[word for word in sample.split]\n",
    "    vocab_obj.update(tokens)\n",
    "\n",
    "def save__vocab_list(vocab,filename):\n",
    "    lines=[a for a in vocab.keys()]\n",
    "    #convert lines to single blob text\n",
    "    data='\\n'.join(lines)\n",
    "    #open file\n",
    "    file=open(filename,'w',encoding='utf-8')\n",
    "    #write text\n",
    "    file.write(data)\n",
    "    #close file\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bad463",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=Counter()\n",
    "for text in final_data['correct_text']:\n",
    "    build_vocab(vocab,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc4387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vocab.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21b4bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=\" \".join([x[0] for x in vocab.most_common(50)])\n",
    "\n",
    "wordcloud = WordCloud(width = 800, height = 800, background_color ='black', min_font_size = 10).generate(g)\n",
    "  \n",
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "#plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee14b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "save__vocab_list(vocab,'vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d9829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer=Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "def encode_docs(tokenizer, max_length, docs):\n",
    "    # integer encode\n",
    "    encoded = tokenizer.texts_to_sequences(docs)\n",
    "    # pad sequences\n",
    "    padded = pad_sequences(encoded, maxlen=max_length, padding='post')\n",
    "    return padded\n",
    "\n",
    "#definer the model\n",
    "def define_model(vocab_size,max_length,n_words):\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab_size,100,input_length=max_length))\n",
    "    model.add(Flatten(input_shape=(n_words,)))\n",
    "    model.add(Dense(45, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(0.0001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b6055",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=final_data['corerct_text']\n",
    "y=final_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a63bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33,random=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5938ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.fillna(\"\",axis=0,inplace=True)\n",
    "X_test.fillna(\"\",axis=0,inplace=True)\n",
    "y_train.fillna(0.0, inplace=True)\n",
    "y_test.fillna(1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3641d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set=set([x for x in vocab if len(x)>2])\n",
    "\n",
    "tokenizer=create_tokenizer(X_train.values)\n",
    "vocab_size=len(tokenizer.word_index)+1\n",
    "max_length=max([len(s.split()) for s in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030329c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=encode_docs(tokenizer,max_length,X_train.values)\n",
    "x_test=encode_docs(tokenizer,max_length,X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26552f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model=define_model(vocab_size,max_length,x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e150798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model.fit(x_train,y_train.values,epochs=10,verbose=2,batch_size=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e94fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model.evaluate(x_train,y_train,verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model.evaluate(x_test, y_test, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6363b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model.predict(x_test[0].reshape(1,-1))[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0b1d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, vocab=vocab_set, tokenizer=tokenizer, max_length=max_length, model=clf_model):\n",
    "    line = text\n",
    "    # clean review\n",
    "    line = clean_text(line)\n",
    "    line = correct_text(line)\n",
    "    line = \" \".join([word for word in line.split() if word in vocab])\n",
    "    # encode and pad review\n",
    "    padded = encode_docs(tokenizer, max_length, [line])\n",
    "    # predict sentiment\n",
    "    yhat = model.predict(padded, verbose=0)\n",
    "#     print(yhat)\n",
    "    # retrieve predicted percentage and label\n",
    "    percent_pos = yhat[0,0]\n",
    "    if round(percent_pos) == 0:\n",
    "        return (1-percent_pos), 'NEGATIVE'\n",
    "    return percent_pos, 'POSITIVE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d870c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(final_data['correct_text'][200],vocab_set,tokenizer,max_length,clf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d979868",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.model.save('clf_seq.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe4acf",
   "metadata": {},
   "source": [
    "# Explainable AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ec4749",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb75e921",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=x_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb46b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer=shap.DeepExplainer(clf_model,np.asarray(samples))\n",
    "shap_values=explainer.shap_values(x_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14802ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values,feature_names=list(vocab_set),class_names=[\"NEGATIVE\",\"POSITIVE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2b35a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(exlainer.expected_value[0],shap_values[0],feature_names=[sentence for sentence in X_test[:10].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1889f80b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee839ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bdbd14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
